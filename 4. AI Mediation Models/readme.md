# AI Moderation Models

AI **Moderation Models** are used to detect and filter inappropriate, harmful, or non-compliant content in online platforms, ensuring safer interactions. Here are some commonly used moderation models:

### **1. Meta Llama Guard 3 (8B & 2B)**  
- **Developed by:** Meta  
- **Purpose:** Detects policy-violating content in conversations, covering hate speech, violence, self-harm, and more.  
- **Features:**  
  - **Llama Guard 3 8B:** More accurate, suited for high-scale moderation.  
  - **Llama Guard 3 2B:** Lighter model for real-time applications.  
- **Use Case:** Content moderation for AI chatbots, social media platforms.

### **2. OpenAI Moderation Model**  
- **Developed by:** OpenAI  
- **Purpose:** Filters harmful content in text-based applications.  
- **Features:**  
  - Detects violence, hate speech, harassment, and sexual content.  
  - Used for GPT-4 and GPT-3.5 moderation.  
- **Use Case:** AI assistant safety, automated content filtering.

### **3. Google Jigsaw Perspective API**  
- **Developed by:** Google Jigsaw  
- **Purpose:** Analyzes text toxicity in online conversations.  
- **Features:**  
  - Provides toxicity scores based on categories like insult, threat, or identity-based hate.  
  - API-based service for integration.  
- **Use Case:** Forum and comment section moderation.

### **4. Anthropic Constitutional AI**  
- **Developed by:** Anthropic  
- **Purpose:** Self-moderating AI based on ethical principles.  
- **Features:**  
  - Designed for AI systems like Claude.  
  - Uses predefined ethical "Constitution" for safer AI responses.  
- **Use Case:** AI-driven customer support and chatbot safety.

### **5. AWS & Azure AI Content Moderation**  
- **AWS Comprehend & Rekognition:**  
  - Detects toxic text and harmful images/videos.  
- **Azure Content Moderator:**  
  - Identifies offensive language, personally identifiable information (PII), and adult content.  
- **Use Case:** Enterprise content moderation for user-generated content.

Each of these models is tailored to different applications, from real-time chatbot safety to large-scale social media moderation.