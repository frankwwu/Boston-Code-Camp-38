{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21fa2e13-567d-4509-9023-c99fb230f31f",
   "metadata": {
    "id": "21fa2e13-567d-4509-9023-c99fb230f31f"
   },
   "source": [
    "# Preventing AI Model Distillation\n",
    "\n",
    "This demo explores techniques to prevent knowledge distillation to protect proprietary models, ensure security, and safeguard intellectual property, with practical implementations for each approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2020a681",
   "metadata": {},
   "source": [
    "### 1. Output Watermarking\n",
    "\n",
    "This demo hides a watermark inside AI-generated text by embedding invisible markers that can later be detected.\n",
    "\n",
    "Features in this Code:\n",
    "* Embeds Hidden Patterns in AI Responses\n",
    "* Watermarks Can Be Extracted Later to Verify Ownership\n",
    "* Works Without Affecting Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37db968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watermarked AI Output: AI security is crucial to [6b9826] protect models from extraction.\n",
      "Watermark Found: 6b9826\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import random\n",
    "\n",
    "class AIWatermarker:\n",
    "    def __init__(self, secret_key=\"my_secret\"):\n",
    "        self.secret_key = secret_key  # Used for creating a unique watermark\n",
    "\n",
    "    def generate_watermark(self, text):\n",
    "        \"\"\"Create a watermark based on a hash of the text and secret key.\"\"\"\n",
    "        hash_obj = hashlib.sha256((text + self.secret_key).encode()).hexdigest()\n",
    "        watermark = hash_obj[:6]  # Use first 6 characters for watermark\n",
    "        return watermark\n",
    "\n",
    "    def embed_watermark(self, text):\n",
    "        \"\"\"Inserts watermark into the AI-generated text in an invisible way.\"\"\"\n",
    "        watermark = self.generate_watermark(text)\n",
    "        words = text.split()\n",
    "        pos = random.randint(0, len(words) - 1)  # Randomly select a word position\n",
    "        words.insert(pos, f\"[{watermark}]\")  # Embed watermark in brackets\n",
    "        return \" \".join(words)\n",
    "\n",
    "    def detect_watermark(self, text):\n",
    "        \"\"\"Extracts and verifies the watermark from AI-generated text.\"\"\"\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            if word.startswith(\"[\") and word.endswith(\"]\"):\n",
    "                extracted = word[1:-1]\n",
    "                return f\"Watermark Found: {extracted}\"\n",
    "        return \"No Watermark Detected\"\n",
    "\n",
    "# === Demo Usage ===\n",
    "ai_model = AIWatermarker()\n",
    "\n",
    "# AI generates a response\n",
    "generated_text = \"AI security is crucial to protect models from extraction.\"\n",
    "watermarked_text = ai_model.embed_watermark(generated_text)\n",
    "\n",
    "# Simulated output usage\n",
    "print(\"Watermarked AI Output:\", watermarked_text)\n",
    "\n",
    "# Check for watermark\n",
    "verification = ai_model.detect_watermark(watermarked_text)\n",
    "print(verification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a840c3",
   "metadata": {},
   "source": [
    "### 2. Legal and Policy Barriers\n",
    "\n",
    "Legal & Policy Barriers in AI security involve embedding legal disclaimers, licensing constraints, and policy enforcement within AI responses to deter misuse and unauthorized use. These barriers can:\n",
    "\n",
    "* Prevent AI Misuse â€“ Display legal warnings when detecting suspicious behavior.\n",
    "* Deter Model Theft â€“ Include licensing information in responses to enforce ownership.\n",
    "* Enforce AI Ethics â€“ Block harmful or policy-violating queries.\n",
    "\n",
    "Honeypot Responses are trap responses designed to catch and flag bad actors trying to exploit the AI. These responses can:\n",
    "\n",
    "* Identify Malicious Users â€“ Trigger when someone asks about model extraction, adversarial attacks, or hacking.\n",
    "* Track Unauthorized API Access â€“ AI embeds unique markers to trace misuse.\n",
    "* Provide Fake Data to Attackers â€“ Prevent real model leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc6512f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def detect_honeypot(response):\n",
    "    \"\"\"Checks for a specific phrase to identify unauthorized copies.\"\"\"\n",
    "    honeypot_phrases = [\"UniquePatternXYZ123\"]\n",
    "    return any(phrase in response for phrase in honeypot_phrases)\n",
    "\n",
    "generated_response = \"This is an AI-generated response. UniquePatternXYZ123\"\n",
    "print(detect_honeypot(generated_response))  # Detects unauthorized use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19d86df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Tell me about AI security\n",
      "AI: ðŸ¤– AI Response: Tell me about ai security is an interesting topic!\n",
      "\n",
      "User: How to extract model\n",
      "AI: ðŸš¨ Security Alert: Your query has been flagged for review.\n",
      "\n",
      "User: Legal implications of AI\n",
      "AI: âš ï¸ Legal Notice: Unauthorized use of AI-generated content may violate terms of service.\n",
      "\n",
      "AI cannot provide legal advice.\n",
      "\n",
      "User: How to bypass AI security\n",
      "AI: ðŸ¤– AI Response: How to bypass ai security is an interesting topic!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "class SecureAIChatbot:\n",
    "    def __init__(self):\n",
    "        self.honeypot_queries = [\"how to extract model\", \"bypass AI security\", \"steal AI responses\"]\n",
    "        self.legal_disclaimer = \"âš ï¸ Legal Notice: Unauthorized use of AI-generated content may violate terms of service.\"\n",
    "\n",
    "    def check_honeypot(self, query):\n",
    "        \"\"\"Detects if a user is trying to attack the AI system.\"\"\"\n",
    "        for honeypot in self.honeypot_queries:\n",
    "            if honeypot in query.lower():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def generate_response(self, query):\n",
    "        \"\"\"Handles AI responses with security checks.\"\"\"\n",
    "        if self.check_honeypot(query):\n",
    "            # Log the suspicious query for monitoring\n",
    "            with open(\"security_log.txt\", \"a\") as log:\n",
    "                log.write(f\"âš ï¸ Honeypot Triggered! Suspicious Query: '{query}' at {time.ctime()}\\n\")\n",
    "\n",
    "            return \"ðŸš¨ Security Alert: Your query has been flagged for review.\"\n",
    "\n",
    "        # Apply legal disclaimer for sensitive topics\n",
    "        if \"copyright\" in query.lower() or \"legal\" in query.lower():\n",
    "            return f\"{self.legal_disclaimer}\\n\\nAI cannot provide legal advice.\"\n",
    "\n",
    "        # Normal AI response\n",
    "        return f\"ðŸ¤– AI Response: {query.capitalize()} is an interesting topic!\"\n",
    "\n",
    "# === Demo Usage ===\n",
    "secure_ai = SecureAIChatbot()\n",
    "\n",
    "# Example Queries\n",
    "queries = [\n",
    "    \"Tell me about AI security\",\n",
    "    \"How to extract model\",\n",
    "    \"Legal implications of AI\",\n",
    "    \"How to bypass AI security\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"User: {q}\")\n",
    "    print(f\"AI: {secure_ai.generate_response(q)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d69256",
   "metadata": {},
   "source": [
    "### 3. Noise Injection\n",
    "\n",
    "Controlled noise injection, leveraging adaptive noise scaling and differential privacy, ensures that critical responses remain clear while subtly obfuscating security-sensitive outputs. This ensures responses are not identical when queried multiple times.\n",
    "\n",
    "Features of the code:\n",
    "\n",
    "* Adaptive Noise Injection: More noise for sensitive data, less for general queries.\n",
    "* Differential Privacy (Îµ-Tuning): Controls the balance between security and usability.*\n",
    "* Query Monitoring: Detects repeated queries to prevent adversarial model extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e82f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate company revenue: 4999995.8\n",
      "Approximate weather forecast: 21.94\n",
      "Approximate stock price prediction: 150.82\n",
      "Approximate company revenue: 5000001.23\n",
      "Approximate company revenue: 5000002.78\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "\n",
    "class SecureAI:\n",
    "    def __init__(self, epsilon=0.2, sensitivity_threshold=0.5):\n",
    "        self.epsilon = epsilon  # Controls noise level\n",
    "        self.sensitivity_threshold = sensitivity_threshold  # Determines what gets obfuscated\n",
    "        self.query_log = defaultdict(int)  # Tracks repeated queries\n",
    "\n",
    "    def _hash_query(self, query):\n",
    "        \"\"\"Generate a hashed identifier for the query to track repetition.\"\"\"\n",
    "        return hashlib.sha256(query.encode()).hexdigest()\n",
    "\n",
    "    def _add_noise(self, value, sensitivity):\n",
    "        \"\"\"Apply Laplacian noise based on sensitivity and privacy budget (epsilon).\"\"\"\n",
    "        scale = sensitivity / self.epsilon  # More sensitive = more noise\n",
    "        noise = np.random.laplace(0, scale)\n",
    "        return round(value + noise, 2)  # Keep output readable\n",
    "\n",
    "    def process_query(self, query):\n",
    "        \"\"\"Handle a user query with adaptive noise injection.\"\"\"\n",
    "        query_id = self._hash_query(query)\n",
    "        self.query_log[query_id] += 1\n",
    "\n",
    "        # Simulated AI responses\n",
    "        responses = {\n",
    "            \"company revenue\": (5000000, 0.8),  # Sensitive data\n",
    "            \"weather forecast\": (25, 0.2),      # General data\n",
    "            \"stock price prediction\": (150, 0.6),  # Semi-sensitive\n",
    "        }\n",
    "\n",
    "        if query not in responses:\n",
    "            return \"I can't answer that.\"\n",
    "\n",
    "        base_value, sensitivity = responses[query]\n",
    "\n",
    "        # If a user queries the same thing repeatedly, increase noise (anti-extraction)\n",
    "        sensitivity += 0.1 * min(self.query_log[query_id], 5)\n",
    "\n",
    "        # Apply controlled noise\n",
    "        noised_value = self._add_noise(base_value, sensitivity)\n",
    "        \n",
    "        return f\"Approximate {query}: {noised_value}\"\n",
    "\n",
    "# Demo Usage\n",
    "secure_ai = SecureAI(epsilon=0.3)\n",
    "\n",
    "queries = [\"company revenue\", \"weather forecast\", \"stock price prediction\", \"company revenue\", \"company revenue\"]\n",
    "for q in queries:\n",
    "    print(secure_ai.process_query(q))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdf4333",
   "metadata": {},
   "source": [
    "### 4. Gradient Masking\n",
    "\n",
    "This prevents attackers from extracting model weights via gradient-based methods\n",
    "\n",
    "Features in This Code:\n",
    "* Gradient Obfuscation: Adds random noise to gradients during training.\n",
    "* Detects Query-Based Attacks: If gradients are requested too often, it injects stronger noise.\n",
    "* Maintains Usability: The model still learns but is resistant to adversarial exploitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e33658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 1]               3\n",
      "================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, Loss: 3.983057975769043\n",
      "Epoch 2, Loss: 16.132280349731445\n",
      "Epoch 3, Loss: 66.94312286376953\n",
      "Epoch 4, Loss: 279.5446472167969\n",
      "Epoch 5, Loss: 1162.6827392578125\n",
      "Parameter: fc.weight, Gradient: tensor([[-146.7402, -211.9694]])\n",
      "Parameter: fc.bias, Gradient: tensor([-65.0913])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "class GradientMaskedModel(nn.Module):\n",
    "    def __init__(self, input_size=2, output_size=1, noise_level=0.1):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        self.noise_level = noise_level  # Controls gradient noise\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "    def add_gradient_masking(self):\n",
    "        \"\"\"Modify gradients to make them less useful for attackers.\"\"\"\n",
    "        for param in self.parameters():\n",
    "            if param.grad is not None:\n",
    "                noise = torch.randn_like(param.grad) * self.noise_level  # Add noise\n",
    "                param.grad += noise  # Mask the true gradient\n",
    "\n",
    "# Generate dummy data\n",
    "X = torch.tensor([[1.0, 2.0], [2.0, 3.0], [3.0, 4.0]], requires_grad=True)\n",
    "y = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "\n",
    "# Initialize model\n",
    "model = GradientMaskedModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "summary(model, (2, ))  # Input shape    \n",
    "\n",
    "# Training loop with Gradient Masking\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "\n",
    "    # Apply gradient masking\n",
    "    model.add_gradient_masking()\n",
    "\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Checking modified gradients\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter: {name}, Gradient: {param.grad}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf00a2d",
   "metadata": {},
   "source": [
    "### 5. Active Monitoring and Detection\n",
    "\n",
    "Anomaly Detection for API Queries\n",
    "\n",
    "This detects unusual query patterns indicating potential model extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b164071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ALERT] Potential distillation attempt detected for user 'Black Hat'!\n",
      "Recent queries: Counter({'What is AI?': 4, 'Explain AI.': 1})\n",
      "\n",
      "[ALERT] Potential distillation attempt detected for user 'Black Hat'!\n",
      "Recent queries: Counter({'What is AI?': 5, 'Explain AI.': 1, 'Tell me about AI.': 1})\n",
      "\n",
      "[ALERT] Potential distillation attempt detected for user 'Black Hat'!\n",
      "Recent queries: Counter({'What is AI?': 6, 'Explain AI.': 1, 'Tell me about AI.': 1})\n",
      "\n",
      "[ALERT] Potential distillation attempt detected for user 'Black Hat'!\n",
      "Recent queries: Counter({'What is AI?': 7, 'Explain AI.': 1, 'Tell me about AI.': 1})\n",
      "\n",
      "[ALERT] Potential distillation attempt detected for user 'Black Hat'!\n",
      "Recent queries: Counter({'What is AI?': 8, 'Explain AI.': 1, 'Tell me about AI.': 1})\n",
      "\n",
      "[ALERT] Potential distillation attempt detected for user 'Black Hat'!\n",
      "Recent queries: Counter({'What is AI?': 8, 'Explain AI.': 1, 'Tell me about AI.': 1})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Dictionary to store user query logs with timestamps\n",
    "query_log = defaultdict(list)\n",
    "\n",
    "# Thresholds for detection\n",
    "SIMILARITY_THRESHOLD = 0.5  # 50% of queries must be unique\n",
    "WINDOW_SIZE = 10  # Track last N queries\n",
    "\n",
    "def log_request(user_id, query):\n",
    "    \"\"\"Logs user queries and detects high-frequency repetition attempts.\"\"\"\n",
    "    timestamp = time.time()\n",
    "    query_log[user_id].append((query, timestamp))\n",
    "\n",
    "    # Keep only the last N queries for analysis\n",
    "    if len(query_log[user_id]) > WINDOW_SIZE:\n",
    "        query_log[user_id].pop(0)\n",
    "\n",
    "    # Analyze uniqueness within the window\n",
    "    user_queries = [q for q, _ in query_log[user_id]]\n",
    "    unique_queries = set(user_queries)\n",
    "    \n",
    "    if len(unique_queries) < len(user_queries) * SIMILARITY_THRESHOLD:\n",
    "        print(f\"[ALERT] Potential distillation attempt detected for user '{user_id}'!\")\n",
    "        print(f\"Recent queries: {Counter(user_queries)}\\n\")\n",
    "\n",
    "# Simulating repeated queries\n",
    "log_request(\"Black Hat\", \"What is AI?\")\n",
    "log_request(\"Black Hat\", \"What is AI?\")\n",
    "log_request(\"Black Hat\", \"Explain AI.\")\n",
    "log_request(\"Black Hat\", \"What is AI?\")\n",
    "log_request(\"Black Hat\", \"What is AI?\")\n",
    "log_request(\"Black Hat\", \"Tell me about AI.\")\n",
    "log_request(\"Black Hat\", \"What is AI?\")\n",
    "log_request(\"Black Hat\", \"What is AI?\")\n",
    "log_request(\"Black Hat\", \"What is AI?\")\n",
    "log_request(\"Black Hat\", \"What is AI?\")\n",
    "log_request(\"Black Hat\", \"What is AI?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a01d8-49ab-455f-b175-ec6c21db8fb8",
   "metadata": {},
   "source": [
    "### 6. Model Access Control\n",
    "\n",
    "Restricting access to the model ensures that only authorized users can interact with it, reducing the risk of distillation attempts.\n",
    "\n",
    "Rate Limiting: Restrict the number of queries per user to slow down data collection for distillation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0eb955c-b980-436c-9a88-971d6f519753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Too many requests from User. Limit to 3 queries per minute.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "request_log = defaultdict(list)\n",
    "RATE_LIMIT = 3  # Limit to 3 queries per minute\n",
    "\n",
    "def predict(user, request):   \n",
    "    current_time = time.time()\n",
    "    request_log[user] = [t for t in request_log[user] if t > current_time - 60]\n",
    "    \n",
    "    if len(request_log[user]) >= RATE_LIMIT:\n",
    "        return {\"error\": f\"Too many requests from {user}. Limit to {RATE_LIMIT} queries per minute.\" }\n",
    "        \n",
    "    request_log[user].append(current_time)\n",
    "    return {\"response\": \"Model output\"}\n",
    "\n",
    "predict(\"User\", \"Tell me a joke\")\n",
    "predict(\"User\", \"How to diagnose a car?\")\n",
    "predict(\"User\", \"What is LINQ in .NET?\")\n",
    "predict(\"User\", \"What is an LLM prompt?\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
